{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \ud83d\udef0\ufe0f Phase 1 + Phase 2: Complete Tracking Pipeline",
    "",
    "**Purpose**: Demonstrate end-to-end tracking from simulation to validated tracks",
    "",
    "**Author**: Space AI Project  ",
    "**Date**: 2026-02-04",
    "",
    "---",
    "",
    "## Overview",
    "",
    "This notebook demonstrates the complete tracking pipeline:",
    "",
    "**Phase 1 (Simulation)**:",
    "- Ground truth orbital trajectories",
    "- Sensor measurements with realistic noise",
    "- Data quality and coverage analysis",
    "",
    "**Phase 2 (Tracking)**:",
    "- Multi-object tracking with Kalman filters",
    "- Data association (Hungarian algorithm)",
    "- Track lifecycle management",
    "- Maneuver detection",
    "",
    "**Phase 3 (Validation)**:",
    "- Performance metrics (RMSE, completeness)",
    "- Error analysis",
    "- Track quality assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup",
    "import sys",
    "sys.path.append('..')",
    "",
    "import pandas as pd",
    "import numpy as np",
    "import matplotlib.pyplot as plt",
    "import seaborn as sns",
    "from pathlib import Path",
    "from datetime import datetime",
    "",
    "# Phase 1 imports",
    "from src.simulation.data_generator import Dataset",
    "from src.utils.coordinates import eci_to_geodetic",
    "",
    "# Phase 2 imports",
    "from src.tracking import MultiObjectTracker, Measurement",
    "",
    "# Configure plotting",
    "plt.style.use('seaborn-v0_8-darkgrid')",
    "sns.set_palette('husl')",
    "%matplotlib inline",
    "",
    "print(\"\u2705 All imports successful\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Phase 1 - Simulation Data",
    "",
    "Load and explore the synthetic tracking dataset generated in Phase 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset",
    "print(\"=\"*60)",
    "print(\"PHASE 1: SIMULATION DATA\")",
    "print(\"=\"*60)",
    "",
    "dataset_path = Path('../data/processed/quick_test')",
    "dataset = Dataset.load(dataset_path)",
    "",
    "print(f\"\\n\ud83d\udce6 Dataset: {dataset_path.name}\")",
    "print(f\"  \u2022 Objects: {len(dataset.ground_truth['object_id'].unique())}\")",
    "print(f\"  \u2022 Ground truth points: {len(dataset.ground_truth)}\")",
    "print(f\"  \u2022 Measurements: {len(dataset.measurements)}\")",
    "print(f\"  \u2022 Sensors: {len(dataset.measurements['sensor_id'].unique())}\")",
    "print(f\"  \u2022 Time span: {(dataset.ground_truth['time'].max() - dataset.ground_truth['time'].min()).total_seconds() / 3600:.2f} hours\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize Phase 1 data",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))",
    "",
    "# Plot 1: Measurement coverage over time",
    "measurements_df = dataset.measurements.copy()",
    "measurements_df['time_hours'] = (measurements_df['time'] - measurements_df['time'].min()).dt.total_seconds() / 3600",
    "axes[0, 0].scatter(measurements_df['time_hours'], measurements_df['object_id'], alpha=0.6, s=20, c=measurements_df['sensor_id'].astype('category').cat.codes)",
    "axes[0, 0].set_xlabel('Time (hours)')",
    "axes[0, 0].set_ylabel('Object ID')",
    "axes[0, 0].set_title('Measurement Coverage (Phase 1)')",
    "axes[0, 0].grid(True, alpha=0.3)",
    "",
    "# Plot 2: Measurements per sensor",
    "sensor_counts = measurements_df.groupby('sensor_id').size()",
    "axes[0, 1].bar(range(len(sensor_counts)), sensor_counts.values)",
    "axes[0, 1].set_xlabel('Sensor ID')",
    "axes[0, 1].set_ylabel('Number of Measurements')",
    "axes[0, 1].set_title('Measurements per Sensor')",
    "axes[0, 1].set_xticks(range(len(sensor_counts)))",
    "axes[0, 1].set_xticklabels(sensor_counts.index)",
    "axes[0, 1].grid(True, alpha=0.3)",
    "",
    "# Plot 3: Ground truth trajectories (2D projection)",
    "gt_df = dataset.ground_truth.copy()",
    "for obj_id in gt_df['object_id'].unique()[:5]:  # First 5 objects",
    "    obj_data = gt_df[gt_df['object_id'] == obj_id]",
    "    axes[1, 0].plot(obj_data['x'], obj_data['y'], alpha=0.7, label=f'Object {obj_id}')",
    "axes[1, 0].set_xlabel('X (km)')",
    "axes[1, 0].set_ylabel('Y (km)')",
    "axes[1, 0].set_title('Ground Truth Trajectories (XY Plane)')",
    "axes[1, 0].legend(fontsize=8)",
    "axes[1, 0].grid(True, alpha=0.3)",
    "axes[1, 0].axis('equal')",
    "",
    "# Plot 4: Altitude distribution",
    "altitudes = np.sqrt(gt_df['x']**2 + gt_df['y']**2 + gt_df['z']**2) - 6378.137",
    "axes[1, 1].hist(altitudes, bins=30, edgecolor='black', alpha=0.7)",
    "axes[1, 1].set_xlabel('Altitude (km)')",
    "axes[1, 1].set_ylabel('Count')",
    "axes[1, 1].set_title('Altitude Distribution')",
    "axes[1, 1].grid(True, alpha=0.3)",
    "",
    "plt.tight_layout()",
    "plt.show()",
    "",
    "print(\"\\n\u2705 Phase 1 data visualized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Phase 2 - Multi-Object Tracking",
    "",
    "Run the tracking pipeline on the simulation data to generate tracks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure and run tracker",
    "print(\"\\n\" + \"=\"*60)",
    "print(\"PHASE 2: MULTI-OBJECT TRACKING\")",
    "print(\"=\"*60)",
    "",
    "# Configure tracker",
    "tracker = MultiObjectTracker(",
    "    filter_type=\"ukf\",",
    "    association_method=\"hungarian\",",
    "    confirmation_threshold=3,",
    "    deletion_threshold=5,",
    "    maneuver_detection_enabled=True",
    ")",
    "",
    "print(f\"\\n\u2699\ufe0f  Tracker Configuration:\")",
    "print(f\"  \u2022 Filter: UKF\")",
    "print(f\"  \u2022 Association: Hungarian\")",
    "print(f\"  \u2022 Maneuver detection: Enabled\")",
    "",
    "# Process measurements",
    "print(f\"\\n\ud83d\udd04 Processing {len(measurements_df)} measurements...\")",
    "",
    "# Create numeric timestamp column (seconds from start)",
    "measurements_df['timestamp'] = (measurements_df['time'] - measurements_df['time'].min()).dt.total_seconds()",
    "",
    "# Group by timestamp",
    "grouped = measurements_df.groupby('timestamp')",
    "timestamps = sorted(grouped.groups.keys())",
    "",
    "all_tracks = []",
    "update_count = 0",
    "",
    "for timestamp in timestamps:",
    "    # Get measurements at this time",
    "    meas_group = grouped.get_group(timestamp)",
    "    ",
    "    # Convert to Measurement objects",
    "    measurements = []",
    "    for idx, row in meas_group.iterrows():",
    "        meas = Measurement(",
    "            position=np.array([row['measured_x'], row['measured_y'], row['measured_z']]),",
    "            covariance=np.eye(3) * 0.05**2,  # 50m std dev",
    "            timestamp=timestamp,",
    "            sensor_id=row['sensor_id'],",
    "            measurement_id=int(idx)",
    "        )",
    "        measurements.append(meas)",
    "    ",
    "    # Update tracker",
    "    tracks = tracker.update(measurements, timestamp)",
    "    ",
    "    # Record track states",
    "    for track in tracks:",
    "        all_tracks.append({",
    "            'timestamp': timestamp,",
    "            'track_id': track.track_id,",
    "            'state': track.state.value,",
    "            'x': track.get_position()[0],",
    "            'y': track.get_position()[1],",
    "            'z': track.get_position()[2],",
    "            'vx': track.get_velocity()[0],",
    "            'vy': track.get_velocity()[1],",
    "            'vz': track.get_velocity()[2],",
    "            'hit_count': track.hit_count,",
    "            'miss_count': track.miss_count,",
    "            'is_maneuvering': track.is_maneuvering,",
    "            'uncertainty': track.get_position_uncertainty()",
    "        })",
    "    ",
    "    update_count += 1",
    "",
    "tracks_df = pd.DataFrame(all_tracks)",
    "",
    "print(f\"\u2705 Tracking complete!\")",
    "print(f\"  \u2022 Updates processed: {update_count}\")",
    "print(f\"  \u2022 Track states recorded: {len(tracks_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display tracker statistics",
    "stats = tracker.get_statistics()",
    "maneuver_events = tracker.get_maneuver_events()",
    "",
    "print(\"\\n\ud83d\udcca Tracking Statistics:\")",
    "print(f\"  \u2022 Total tracks: {stats['total_tracks']}\")",
    "print(f\"  \u2022 Confirmed tracks: {stats['confirmed_tracks']}\")",
    "print(f\"  \u2022 Tentative tracks: {stats['tentative_tracks']}\")",
    "print(f\"  \u2022 Association rate: {stats['association_rate']:.1%}\")",
    "print(f\"  \u2022 Maneuver events: {len(maneuver_events)}\")",
    "",
    "if len(maneuver_events) > 0:",
    "    print(f\"\\n\u26a0\ufe0f  Maneuver Events Detected:\")",
    "    for event in maneuver_events[:5]:  # Show first 5",
    "        print(f\"  \u2022 Track {event.track_id} at t={event.timestamp:.1f}s (confidence: {event.confidence:.1%})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize Phase 2 results",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))",
    "",
    "# Plot 1: Track states over time",
    "for state in tracks_df['state'].unique():",
    "    state_data = tracks_df[tracks_df['state'] == state]",
    "    axes[0, 0].scatter(state_data['timestamp'], state_data['track_id'], ",
    "                      label=state.upper(), alpha=0.6, s=20)",
    "axes[0, 0].set_xlabel('Time (s)')",
    "axes[0, 0].set_ylabel('Track ID')",
    "axes[0, 0].set_title('Track States Over Time')",
    "axes[0, 0].legend()",
    "axes[0, 0].grid(True, alpha=0.3)",
    "",
    "# Plot 2: Track completeness (hits per track)",
    "confirmed_tracks = tracks_df[tracks_df['state'] == 'confirmed']",
    "if len(confirmed_tracks) > 0:",
    "    track_hits = confirmed_tracks.groupby('track_id')['hit_count'].max()",
    "    axes[0, 1].bar(range(len(track_hits)), track_hits.values)",
    "    axes[0, 1].set_xlabel('Track ID')",
    "    axes[0, 1].set_ylabel('Hit Count')",
    "    axes[0, 1].set_title('Track Completeness (Confirmed Tracks)')",
    "    axes[0, 1].set_xticks(range(len(track_hits)))",
    "    axes[0, 1].set_xticklabels(track_hits.index)",
    "    axes[0, 1].grid(True, alpha=0.3)",
    "",
    "# Plot 3: Tracked trajectories (2D projection)",
    "for track_id in tracks_df['track_id'].unique()[:5]:  # First 5 tracks",
    "    track_data = tracks_df[tracks_df['track_id'] == track_id]",
    "    axes[1, 0].plot(track_data['x'], track_data['y'], alpha=0.7, label=f'Track {track_id}')",
    "axes[1, 0].set_xlabel('X (km)')",
    "axes[1, 0].set_ylabel('Y (km)')",
    "axes[1, 0].set_title('Tracked Trajectories (XY Plane)')",
    "axes[1, 0].legend(fontsize=8)",
    "axes[1, 0].grid(True, alpha=0.3)",
    "axes[1, 0].axis('equal')",
    "",
    "# Plot 4: Position uncertainty over time",
    "confirmed_tracks = tracks_df[tracks_df['state'] == 'confirmed']",
    "if len(confirmed_tracks) > 0:",
    "    for track_id in confirmed_tracks['track_id'].unique()[:5]:",
    "        track_data = confirmed_tracks[confirmed_tracks['track_id'] == track_id]",
    "        axes[1, 1].plot(track_data['timestamp'], track_data['uncertainty'], ",
    "                       alpha=0.7, label=f'Track {track_id}')",
    "    axes[1, 1].set_xlabel('Time (s)')",
    "    axes[1, 1].set_ylabel('Position Uncertainty (km)')",
    "    axes[1, 1].set_title('Track Uncertainty Over Time')",
    "    axes[1, 1].legend(fontsize=8)",
    "    axes[1, 1].grid(True, alpha=0.3)",
    "",
    "plt.tight_layout()",
    "plt.show()",
    "",
    "print(\"\\n\u2705 Phase 2 results visualized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Performance Evaluation",
    "",
    "Compare tracked positions against ground truth to measure accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate tracking performance",
    "print(\"\\n\" + \"=\"*60)",
    "print(\"PHASE 3: PERFORMANCE EVALUATION\")",
    "print(\"=\"*60)",
    "",
    "# Prepare ground truth with timestamps",
    "gt_df['timestamp'] = (gt_df['time'] - gt_df['time'].min()).dt.total_seconds()",
    "",
    "# Merge tracks with ground truth (assuming track_id == object_id)",
    "merged = pd.merge(",
    "    tracks_df[tracks_df['state'] == 'confirmed'],",
    "    gt_df,",
    "    left_on=['timestamp', 'track_id'],",
    "    right_on=['timestamp', 'object_id'],",
    "    how='inner',",
    "    suffixes=('_track', '_truth')",
    ")",
    "",
    "if len(merged) > 0:",
    "    # Compute position errors",
    "    merged['position_error'] = np.sqrt(",
    "        (merged['x_track'] - merged['x_truth'])**2 +",
    "        (merged['y_track'] - merged['y_truth'])**2 +",
    "        (merged['z_track'] - merged['z_truth'])**2",
    "    )",
    "    ",
    "    # Compute velocity errors",
    "    merged['velocity_error'] = np.sqrt(",
    "        (merged['vx_track'] - merged['vx_truth'])**2 +",
    "        (merged['vy_track'] - merged['vy_truth'])**2 +",
    "        (merged['vz_track'] - merged['vz_truth'])**2",
    "    )",
    "    ",
    "    # Metrics",
    "    pos_rmse = np.sqrt(np.mean(merged['position_error']**2))",
    "    pos_mae = np.mean(merged['position_error'])",
    "    vel_rmse = np.sqrt(np.mean(merged['velocity_error']**2))",
    "    vel_mae = np.mean(merged['velocity_error'])",
    "    ",
    "    print(f\"\\n\ud83d\udcca Performance Metrics:\")",
    "    print(f\"  \u2022 Position RMSE: {pos_rmse:.3f} km ({pos_rmse*1000:.1f} m)\")",
    "    print(f\"  \u2022 Position MAE:  {pos_mae:.3f} km ({pos_mae*1000:.1f} m)\")",
    "    print(f\"  \u2022 Velocity RMSE: {vel_rmse:.4f} km/s ({vel_rmse*1000:.2f} m/s)\")",
    "    print(f\"  \u2022 Velocity MAE:  {vel_mae:.4f} km/s ({vel_mae*1000:.2f} m/s)\")",
    "    ",
    "    # Assessment",
    "    print(f\"\\n\u2705 Assessment:\")",
    "    if pos_rmse * 1000 < 100:",
    "        print(f\"  \u2022 Position accuracy: EXCELLENT ({pos_rmse*1000:.1f}m < 100m target) \u2705\")",
    "    elif pos_rmse * 1000 < 200:",
    "        print(f\"  \u2022 Position accuracy: GOOD ({pos_rmse*1000:.1f}m < 200m) \u26a0\ufe0f\")",
    "    else:",
    "        print(f\"  \u2022 Position accuracy: NEEDS IMPROVEMENT ({pos_rmse*1000:.1f}m) \u274c\")",
    "    ",
    "    if vel_rmse * 1000 < 10:",
    "        print(f\"  \u2022 Velocity accuracy: EXCELLENT ({vel_rmse*1000:.2f} m/s < 10 m/s target) \u2705\")",
    "    else:",
    "        print(f\"  \u2022 Velocity accuracy: GOOD ({vel_rmse*1000:.2f} m/s) \u26a0\ufe0f\")",
    "else:",
    "    print(\"\\n\u26a0\ufe0f  No matching tracks found for evaluation\")",
    "    print(\"This may happen if track IDs don't match object IDs or if no tracks were confirmed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize errors",
    "if len(merged) > 0:",
    "    fig, axes = plt.subplots(1, 2, figsize=(15, 5))",
    "    ",
    "    # Position error over time",
    "    axes[0].scatter(merged['timestamp'], merged['position_error'], alpha=0.5, s=10)",
    "    axes[0].axhline(pos_rmse, color='r', linestyle='--', label=f'RMSE: {pos_rmse:.3f} km')",
    "    axes[0].set_xlabel('Time (s)')",
    "    axes[0].set_ylabel('Position Error (km)')",
    "    axes[0].set_title('Position Error Over Time')",
    "    axes[0].legend()",
    "    axes[0].grid(True, alpha=0.3)",
    "    ",
    "    # Error histogram",
    "    axes[1].hist(merged['position_error'], bins=30, edgecolor='black', alpha=0.7)",
    "    axes[1].axvline(pos_rmse, color='r', linestyle='--', label=f'RMSE: {pos_rmse:.3f} km')",
    "    axes[1].set_xlabel('Position Error (km)')",
    "    axes[1].set_ylabel('Count')",
    "    axes[1].set_title('Position Error Distribution')",
    "    axes[1].legend()",
    "    axes[1].grid(True, alpha=0.3)",
    "    ",
    "    plt.tight_layout()",
    "    plt.show()",
    "    ",
    "    print(\"\\n\u2705 Error analysis visualized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary",
    "",
    "This notebook demonstrates the complete tracking pipeline from simulation (Phase 1) through tracking (Phase 2) to validation (Phase 3)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final summary",
    "print(\"\\n\" + \"=\"*60)",
    "print(\"SUMMARY\")",
    "print(\"=\"*60)",
    "",
    "print(f\"\"\"",
    "\u2705 **Phase 1 (Simulation)**: ",
    "   \u2022 Generated {len(measurements_df)} measurements from {len(gt_df['object_id'].unique())} objects",
    "   \u2022 Time span: {(gt_df['time'].max() - gt_df['time'].min()).total_seconds() / 3600:.2f} hours",
    "   \u2022 Sensors: {len(measurements_df['sensor_id'].unique())}",
    "",
    "\u2705 **Phase 2 (Tracking)**: ",
    "   \u2022 Processed {update_count} time steps",
    "   \u2022 Created {stats['total_tracks']} tracks",
    "   \u2022 Confirmed {stats['confirmed_tracks']} tracks",
    "   \u2022 Association rate: {stats['association_rate']:.1%}",
    "   \u2022 Detected {len(maneuver_events)} maneuvers",
    "\"\"\")",
    "",
    "if len(merged) > 0:",
    "    print(f\"\"\"\u2705 **Phase 3 (Evaluation)**:",
    "   \u2022 Position RMSE: {pos_rmse*1000:.1f} m (target: <100m)",
    "   \u2022 Velocity RMSE: {vel_rmse*1000:.2f} m/s (target: <10 m/s)",
    "   \u2022 Matched track states: {len(merged)}",
    "\"\"\")",
    "",
    "print(f\"\"\"",
    "\ud83c\udfaf **Next Steps**:",
    "   1. Test with larger datasets (100+ objects)",
    "   2. Test with real TLE data from CelesTrak",
    "   3. Implement Phase 3 (ML Prediction)",
    "   4. Build operational dashboard (Phase 4)",
    "\"\"\")",
    "",
    "print(\"\u2728 Analysis complete!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (space-ai)",
   "language": "python",
   "name": "space-ai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}